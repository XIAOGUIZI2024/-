# 模型微调的方法
* 全参数微调 
  对原有的数据集进行更新，然后直接训练
* 参数高效微调
  添加部分的数据集进行更新，然后直接训练
* 低秩适应微调
  引入新的低秩矩阵进行微调
* 探针
  在模型的不同层添加简单的分类器，观察器输出的结果
* 逐层冻结
  逐层冻结模型的某些层，使其参数不在更新
# 低秩适应微调的原理（LoRA）
**冻结预训练大模型权重，用两个低秩矩阵的乘积近似权重更新量 ΔW，仅训练这两个小矩阵，以极小参数与算力代价实现任务适配**
1. 冻结预训练模型所有原始权重，仅在目标层（如 Transformer 注意力的 q_proj/v_proj）插入低秩旁路。
2. 初始化 A 为随机高斯分布、B 为零矩阵，避免初始扰动过大破坏预训练表示。
3. 用任务数据训练，仅计算 A、B 的梯度并更新，不触及原始权重。
4. 训练完成后合并 BA 与 W₀，或在推理时动态叠加低秩分支输出。
# Q-LoRA
**是一种结合量化和低秩适应技术的微调方法**
**步骤**
  1. 先通过量化