# rag是什么
**rag 检索增强生成 基于用户的输入从外部知识数据检索与查询相关的文本片段，然后作为上下文发送向ai提问**
# 工作流程
* 索引的创建 （**数据的收集和存储**）
1. 从不同的数据源收集原始文档
2. 清洗这些文档为一个标准的文档格式
3. 把标准化的长文档切割为适当大小的片段（**chunks**）
4. 使用Embedding 模型把文档切片转化为高维向量
5. 把相关的高维向量存储在向量数据库中
* 检索生成
1. 将用户的提问 清洗为一个标准的文档格式
2. 使用 Embedding 模型 转化为相关的向量
3. 查询向量数据库获取相关的向量数据
4. 将获取向量数据的信息组装为输入LLM的上下文
# 检索生成 的优化
## 召回
在查询向量数据库获取相关的向量数据 这个步骤中 向量数据库强调**速度和广度而非精确度**，只会尽可能的收集相关的数据集数量
## 粗排
对召回的数据进行初步的筛选，把返回的数量减少，提高返回数据集的质量
## 精排 和 Rank模型
* 对粗排的内容进行更加精确的排序，进一步提高返回数据集的质量 (及是选出相关的Top-k)
* 消除文档之间的细微语义关系
* 所用的索引的速度较慢，但是精度较好
* 交叉编码器模型 如 BERT
**交叉编码器
- **工作原理**：
    1. 将两个需要比较的文本（例如，一个查询和一个文档，一个前提和一个假设，两个句子）**拼接在一起**，中间用特殊分隔符（如 `[SEP]`）隔开。
        
    2. 将这个拼接后的长序列输入到一个**单一的深度 Transformer 模型**（如 BERT、RoBERTa）中。
        
    3. 模型会同时处理这两个文本，并进行**深度、全面的交互和双向注意力计算**。这意味着在编码过程中，第一个文本的每一个词都能关注到第二个文本的所有词，反之亦然。
        
    4. 最终，模型输出一个**单一的表示**（通常取 `[CLS]` 标记的嵌入），并通过一个分类层来预测这两个文本之间的关系（如相关性分数、蕴含关系、相似度等）
## 混合检索
混合检索的核心思想是 **“取长补短”** ， **传统关键词检索 + 向量/语义检索 
传统关键次检索
- **原理：基于词频、逆向文档频率等统计信息，精确匹配查询词和文档中的词汇
- **代表技术**：BM25（被认为是传统关键词检索的“黄金标准”）
**向量/语义检索
* **原理**：使用深度学习模型（如BERT、Sentence Transformers）将查询和文档都转换为高维向量（嵌入）。通过计算向量间的相似度（如余弦相似度）来检索
**工作原理**
混合检索不是简单地二选一，而是**同时执行两种（或多种）检索，然后融合它们的结果**
**结果融合（Late Fusion / Result Aggregation）**
- **步骤**：
    
    1. 使用**关键词检索**（如BM25）对文档库进行搜索，为每个文档生成一个相关性分数 `S_kw`
        
    2. 同时，使用**向量检索**对文档库进行搜索，为每个文档生成一个语义相似度分数 `S_vec`。
        
    3. 将这两个分数通过一个公式进行**加权合并**，得到最终分数 `S_final`。
        
    4. 根据 `S_final` 对文档进行重新排序，返回给用户
**重排序（Re-ranking）**
- **步骤**：
    
    1. 首先，使用**关键词检索**快速地从海量文档中召回一个初步的、相对较大的候选结果集（例如，前1000个文档）。这一步保证了**召回率**。
        
    2. 然后，使用更强大的**语义模型**（通常是更精细、计算成本更高的模型）对这个较小的候选集进行重新打分和排序。
        
    3. 返回重排序后的顶部结果。
