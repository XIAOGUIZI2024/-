# rag是什么
**rag 检索增强生成 基于用户的输入从外部知识数据检索与查询相关的文本片段，然后作为上下文发送向ai提问**
# 工作流程
* 索引的创建 （**数据的收集和存储**）
1. 从不同的数据源收集原始文档
2. 清洗这些文档为一个标准的文档格式
3. 把标准化的长文档切割为适当大小的片段（**chunks**）
4. 使用Embedding 模型把文档切片转化为高维向量
5. 把相关的高维向量存储在向量数据库中
* 检索生成
1. 将用户的提问 清洗为一个标准的文档格式
2. 使用 Embedding 模型 转化为相关的向量
3. 查询向量数据库获取相关的向量数据
4. 将获取向量数据的信息组装为输入LLM的上下文
# 检索生成 的优化
## 召回
在查询向量数据库获取相关的向量数据 这个步骤中 向量数据库强调**速度和广度而非精确度**，只会尽可能的收集相关的数据集数量
## 粗排
对召回的数据进行初步的筛选，把返回的数量减少，提高返回数据集的质量
## 精排 和 Rank模型
* 对粗排的内容进行更加精确的排序，进一步提高返回数据集的质量 (及是选出相关的Top-k)
* 消除文档之间的细微语义关系
* 所用的索引的速度较慢，但是精度较好
* 交叉编码器模型 如 BERT
**交叉编码器
- **工作原理**：
    1. 将两个需要比较的文本（例如，一个查询和一个文档，一个前提和一个假设，两个句子）**拼接在一起**，中间用特殊分隔符（如 `[SEP]`）隔开。
        
    2. 将这个拼接后的长序列输入到一个**单一的深度 Transformer 模型**（如 BERT、RoBERTa）中。
        
    3. 模型会同时处理这两个文本，并进行**深度、全面的交互和双向注意力计算**。这意味着在编码过程中，第一个文本的每一个词都能关注到第二个文本的所有词，反之亦然。
        
    4. 最终，模型输出一个**单一的表示**（通常取 `[CLS]` 标记的嵌入），并通过一个分类层来预测这两个文本之间的关系（如相关性分数、蕴含关系、相似度等）
## 混合检索策略
结合多种检索的策略来搜索数据